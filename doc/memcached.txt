重要的结构体
typedef struct {
    unsigned int size;      /* sizes of items */
    unsigned int perslab;   /* how many items per slab */

    void *slots;           /* list of item ptrs */
    unsigned int sl_curr;   /* total free items in list */

    unsigned int slabs;     /* how many slabs were allocated for this class */

    void **slab_list;       /* array of slab pointers */
    unsigned int list_size; /* size of prev array */

    size_t requested; /* The number of requested bytes */
} slabclass_t; //(slabs.c)

|-->struct conn //(memcached.h) 每个接入memcached数据库的用户数据结构体
	|-->struct conn {
	    int    sfd;
	    sasl_conn_t *sasl_conn;
	    bool authenticated;
	    enum conn_states  state;
	    enum bin_substates substate;
	    rel_time_t last_cmd_time;
	    struct event event;
	    short  ev_flags;
	    short  which;   /** which events were just triggered */
	
	    char   *rbuf;   /** buffer to read commands into */
	    char   *rcurr;  /** but if we parsed some already, this is where we stopped */
	    int    rsize;   /** total allocated size of rbuf */
	    int    rbytes;  /** how much data, starting from rcur, do we have unparsed */
	
	    char   *wbuf;
	    char   *wcurr;
	    int    wsize;
	    int    wbytes;
	    /** which state to go into after finishing current write */
	    enum conn_states  write_and_go;
	    void   *write_and_free; /** free this memory after finishing writing */
	
	    char   *ritem;  /** when we read in an item's value, it goes here */
		int    rlbytes;
	
	    /* data for the nread state */
	
	    /**
	     * item is used to hold an item structure created after reading the command
	     * line of set/add/replace commands, but before we finished reading the actual
	     * data. The data is read into ITEM_data(item) to avoid extra copying.
	     */
	
	    void   *item;     /* for commands set/add/replace  */
	
	    /* data for the swallow state */
	    int    sbytes;    /* how many bytes to swallow */
	
	    /* data for the mwrite state */
	    struct iovec *iov;
	    int    iovsize;   /* number of elements allocated in iov[] */
	    int    iovused;   /* number of elements used in iov[] */
	
	    struct msghdr *msglist;
	    int    msgsize;   /* number of elements allocated in msglist[] */
	    int    msgused;   /* number of elements used in msglist[] */
	    int    msgcurr;   /* element in msglist[] being transmitted now */
		item   **ilist;   /* list of items to write out */
	    int    isize;
	    item   **icurr;
	    int    ileft;
	
	    char   **suffixlist;
	    int    suffixsize;
	    char   **suffixcurr;
	    int    suffixleft;
	#ifdef EXTSTORE
	    int io_wrapleft;
	    unsigned int recache_counter;
	    io_wrap *io_wraplist; /* linked list of io_wraps */
	    bool io_queued; /* FIXME: debugging flag */
	#endif
	    enum protocol protocol;   /* which protocol this connection speaks */
	    enum network_transport transport; /* what transport is used by this connection */
	
	    /* data for UDP clients */
	    int    request_id; /* Incoming UDP request ID, if this is a UDP "connection" */
	    struct sockaddr_in6 request_addr; /* udp: Who sent the most recent request */
	    socklen_t request_addr_size;
	    unsigned char *hdrbuf; /* udp packet headers */
	    int    hdrsize;   /* number of headers' worth of space is allocated */
	
	    bool   noreply;   /* True if the reply should not be sent. */
		/* current stats command */
	    struct {
	        char *buffer;
	        size_t size;
	        size_t offset;
	    } stats;
	
	    /* Binary protocol stuff */
	    /* This is where the binary header goes */
	    protocol_binary_request_header binary_header;
	    uint64_t cas; /* the cas to return */
	    short cmd; /* current command being processed */
	    int opaque;
	    int keylen;
	    conn   *next;     /* Used for generating a list of conn structures */
	    LIBEVENT_THREAD *thread; /* Pointer to the thread object serving this connection */
	};

#define MAX_NUMBER_OF_SLAB_CLASSES (63 + 1) //(memcached.h)
static slabclass_t slabclass[MAX_NUMBER_OF_SLAB_CLASSES] //(slabs.c) 全局变量

#define HOT_LRU 0 //hot数据区
#define WARM_LRU 64 //warm数据区
#define COLD_LRU 128 //cold数据区
#define TEMP_LRU 192 //没有过期时间数据区

#define CLEAR_LRU(id) (id & ~(3<<6)) //最原始的数据区,即hot数据区
#define GET_LRU(id) (id & (3<<6)) //
#define LARGEST_ID POWER_LARGEST //lru数组最大值256,即0-255

m --> settings.maxbytes
settings.item_size_max > (settings.maxbytes / 2)

|-->main //(memcached.c)
	|-->settings_init //(memcached.c) 设置默认参数，设置settings全局变量的默认参数
		|-->settings.maxbytes = 64 * 1024 * 1024 //(64M)
		|-->settings.factor = 1.25 //
		|-->settings.slab_page_size = 1024 * 1024 //
		|-->settings.slab_chunk_size_max = settings.slab_page_size / 2
		|-->settings.chunk_size = 48
		|-->settings.lru_segmented = true 
		|-->settings.hot_lru_pct = 20 
		|-->settings.warm_lru_pct = 40
		|-->settings.hot_max_factor = 0.2
		|-->settings.warm_max_factor = 2.0
		|-->settings.temp_lru = false
		|-->settings.idle_timeout = 0;
		|-->settings.inter = NULL //
		|-->settings.port = 11211 //
		|-->settings.slab_reassign = true //用于开启slab维护线程
		|-->settings.reqs_per_event = 20 //用于工作线程进行判断，最多只能在conn_new_cmd中连续执行的Request次数
		
	|-->init_lru_maintainer //(items.c) 初始化互斥锁和全局变量
		|-->pthread_mutex_init(&lru_maintainer_lock, NULL) 
		|-->lru_maintainer_initialized = 1 
	
	|-->event_init //调用libevent库，创建事件
	|-->logger_init //(logger.c)
		|-->start_logger_thread //(logger.c)
			|-->do_run_logger_thread = 1
			|-->logger_thread //(logger.c)创建log线程
				|-->while (do_run_logger_thread) //进入loop循环
					|-->logger_thread_read //(logger.c)
						|-->
	
	|-->stats_init //()
	|-->assoc_init //()
	|-->conn_init //()
	|-->slabs_init(settings.maxbytes, settings.factor, preallocate, use_slab_sizes ? slab_sizes : NULL) //(slabs.c)
		|-->
		
	|-->memcached_thread_init //(thread.c)
		|-->pipe(fds) //创建管道用于通信
		|-->threads[i].notify_receive_fd = fds[0] 
		|-->threads[i].notify_send_fd = fds[1] 
		|-->setup_thread //(thread.c)
			|-->event_set(&me->notify_event, me->notify_receive_fd, EV_READ | EV_PERSIST, thread_libevent_process, me)//将notify_receive_fd绑定到thread_libevent_process, 该线程为工作线程,执行真正的数据解析
			|-->event_base_set //
			|-->event_add //
				|-->thread_libevent_process //(thread.c)
					|-->switch(switch (buf[0]))
						|-->case 'c': //由另外一个pipe唤醒
							|-->item = cq_pop(me->new_conn_queue) //获取当前的item
							|-->switch (item->mode) //根据mode来分类执行, listen后会将其置为queue_new_conn
								|-->case queue_new_conn //listen后会将其置为queue_new_conn
									|-->conn_new //(memcached.c) 创建新接入socket的回调绑定函数，用于处理client的数据
										|-->event_set(&c->event, sfd, EV_READ | EV_PERSIST, event_handler, (void *)c)// 设置回调函数
										|-->event_base_set //关联event_base和evnet
										|-->event_add //将fd添加到epoll中
											|-->event_handler //(memcached.c) 数据接收处理，其中conn_listening是listen线程独有的
												|-->drive_machine //(memcached.c)
													|-->stop = false //用于控制while loop循环
													|-->nreqs = settings.reqs_per_event //
													|-->while (!stop) //loop
														|-->switch(c->state)
															|-->case conn_new_cmd //accept后的第一个状态为该状态
																|-->--nreqs //对其做减一处理，用于控制在该状态的最大执行次数
																|-->if (nreqs >= 0) //如果依然有效则进入该分支
																	|-->reset_cmd_handler //(memcached.c)
																		|-->conn_shrink(c) //(memcached.c) 调整内存buff，用于接收处理
																		|-->if (c->rbytes > 0)
																			|-->conn_set_state(c, conn_parse_cmd) //在第一次进入时不会进入该分支，因为此时还未接收任何数据
																		|-->else
																			|-->conn_set_state(c, conn_waiting) //在从listen状态切换到该状态时第一次默认进入该状态，此时数据还未接收
																			
																|-->else //(nreqs < 0)如果已经在该状态执行了最大次数(默认为20次)
																	|-->if (c->rbytes > 0) //如果此时buff中已经有数据
																		|-->update_event(c, EV_WRITE | EV_PERSIST) //设置可写事件, 先删除，后添加
																			|-->event_del(&c->event) //删除事件
																			|-->event_set(&c->event, c->sfd, new_flags, event_handler, (void *)c) //重新加入事件
																			|-->event_base_set(base, &c->event) //
																			|-->event_add(&c->event, 0) //
																		
																	|-->stop = true //退出while循环
																	
															|-->case conn_waiting //从conn_new_cmd迁移到该状态
																|-->update_event(c, EV_READ | EV_PERSIST) //设置可读事件
																|-->conn_set_state(c, conn_read) //设置状态机为conn_read
																|-->stop = true //设置变量，退出while循环，等待对应的fd触发接收事件
																	
															|-->case conn_read //从conn_waiting迁移到该状态，fd中读取数据
																|-->res = try_read_network(c) //(memcached.c)
																	|-->res = read //读取数据
																		|-->if(res > 0)
																			|-->c->thread->stats.bytes_read += res //前后加锁
																			|-->c->rbytes += res //将读取的数据长度赋值到rbytes
															
																		|-->if (res == 0)
																			|-->return READ_ERROR
																			
																		|-->if (res == -1)
																			|-->if (errno == EAGAIN || errno == EWOULDBLOCK)
																				|-->break;
																				
																			|-->return READ_ERROR;
																			
																|-->switch (res)
																	|-->case READ_NO_DATA_RECEIVED //无数据接收
																		|-->conn_set_state(c, conn_waiting) //设置为继续等待
																		
																	|-->READ_DATA_RECEIVED //有数据接收
																		|-->conn_set_state(c, conn_parse_cmd) //正常情况下会进入该状态, 直接进入下一个loop, 到conn_parse_cmd
																	
																	|-->case READ_ERROR //读取失败
																		|-->conn_set_state(c, conn_closing) //设置状态机为conn_closing，再次进入loop
																		
															|-->conn_closing //处理关闭连接
																|-->if (IS_UDP(c->transport))
																	|-->conn_cleanup(c)
																|-->else
																	|-->conn_close //tcp处理方式，最终会调用epoll_ctl将fd删除
																		|-->event_del(&c->event) //调用epoll删除fd
																		|-->conn_cleanup //
																		
																|-->stop = true //退出loop循环
															
															|-->case conn_parse_cmd // conn_read状态到该状态, 处理用户输入的指令
																|-->ret = try_read_command //(memcached.c) 读取指令
																	|-->process_command //(memcached.c)
																		|-->add_msghdr //(memcached.c)
																			|-->

																		|-->tokenize_command //(memcached.c)
																			|-->

																		|-->switch(cmd)
																			|-->case "get" || "bget"
																				|-->process_get_command //()

																			|-->case "add" || "set" || "replace" || "prepend" || "append"
																				|-->process_update_command(c, tokens, ntokens, comm, false)
																					|-->set_noreply_maybe //()
																					|-->判断key值的长度(不能大于250),否则返回错误
																					|-->item_alloc //(thread.c)
																						|-->do_item_alloc //(items.c) 惰性分配
																							|-->item_make_header //(items.c) 计算数据存储长度
																							|-->slabs_clsid //(slabs.c)
																								|-->通过while对比slabclass.size的大小,从而返回对应的索引值(slabclass.szie在slabs_init中预分配)
																							|-->判断种大小是否超过settings.slab_chunk_size_max(该值默认为512K)
																								|-->超过
																									|-->

																								|-->不超过
																									|-->do_item_alloc_pull //(items.c)
																										|-->slabs_alloc //(slabs.c)
																											|-->do_slabs_alloc //(slabs.c)
																												|-->

																					|-->
																					|-->conn_set_state(c, conn_nread) //设置状态机

																			|-->case "cas"
																				|-->process_update_command(c, tokens, ntokens, comm, true)

																			|-->case "inc"
																				|-->process_arithmetic_command//

																			|-->case "gets"
																				|-->process_get_command //()

																			|-->case "decr"
																				|-->process_arithmetic_command //()

																			|-->case "delete"
																				|-->process_delete_command //()

																			|-->case "touch"
																				|-->process_touch_command //()

																			|-->case "gat"
																				|-->process_get_command(c, tokens, ntokens, false, true) //

																			|-->case "gats"
																				|-->process_get_command(c, tokens, ntokens, true, true) //

																			|-->case "stats"
																				|-->process_stat //()

																			|-->case "flush_all"
																				|-->

																			|-->case "version"
																				|-->out_string //

																			|-->case "quit"
																				|-->conn_set_state(c, conn_closing) //

																			|-->case "shutdown"
																				|-->

																			|-->case "slabs"
																				|-->
																	
																|-->if(0 == ret)
																	|-->conn_set_state(c, conn_waiting) //将状态置为waiting状态

		|-->create_worker(worker_libevent, &threads[i]) //(thread.c) 创建工作线程，根据setup_thread设置的参数进行工作
			|-->worker_libevent //(thread.c) 线程工作函数
				|-->register_thread_initialized //(thread.c)
					|-->init_count++ //工作线程创建成功后对init_count，用于统计所有的工作线程是否都已经创建成功
					|-->pthread_cond_signal(&init_cond) //发送条件变量
					|-->pthread_mutex_unlock(&init_lock) //
					|-->pthread_mutex_lock(&worker_hang_lock)
					|-->pthread_mutex_unlock(&worker_hang_lock)
				
				|-->event_base_loop //进入循环，等待epoll_wait的返回并执行函数
				
		|-->wait_for_thread_registration //等待所有的线程注册完毕，否则停在该处
			|-->while (init_count < nthreads)
				|-->pthread_cond_wait(&init_cond, &init_lock);
	
	if(start_assoc_maint) //默认进入该分支
		|-->start_assoc_maintenance_thread //(assoc.c) 默认开启该线程
			|-->assoc_maintenance_thread //(assoc.c)
				|-->while (do_run_maintenance_thread) //进入loop循环,do_run_maintenance_thread初始化为1
					|-->for (ii = 0; ii < hash_bulk_move && expanding; ++ii) //初始状态时无法进入,expanding=false
						|-->

					|-->if (!expanding) //初始状态expanding=false, 进入该状态
						|-->started_expanding = false
						|-->pthread_cond_wait(&maintenance_cond, &maintenance_lock) //(assoc.c) 等待条件变量, 将在clock_handler函数中被唤醒
						|-->assoc_expand //(assoc.c)
							|-->calloc //分配内存
							|-->expanding = true

	
	if(start_lru_crawler) //默认进入该分支
		|-->start_item_crawler_thread //(crawler.c)  默认开启该线程
			|-->do_run_lru_crawler_thread = 1 //设置变量
			|-->item_crawler_thread //(crawler.c)创建线程
				|-->pthread_cond_signal(&lru_crawler_cond) //发送条件变量,告知父线程,已经创建成功
				|-->settings.lru_crawler = true //
				|-->while (do_run_lru_crawler_thread) //进入loop 循环
					|-->pthread_cond_wait(&lru_crawler_cond, &lru_crawler_lock) //等待条件变量

			|-->pthread_cond_wait(&lru_crawler_cond, &lru_crawler_lock) //等待条件变量,否则阻塞在这里
	
	if(settings.slab_reassign) //默认进入该分支
		|-->start_slab_maintenance_thread //(slabs.c)
			|-->pthread_cond_init(&slab_rebalance_cond, NULL) //初始化条件变量
			|-->slab_rebalance_thread //(slabs.c)
				|-->while (do_run_slab_rebalance_thread) //loop
					|-->if (slab_rebalance_signal == 1)
						|-->if (slab_rebalance_start() < 0)
							|-->slab_rebalance_signal  = 1
					
						|-->was_busy = 0
						
					|-->else if (slab_rebalance_signal && slab_rebal.slab_start != NULL)
						|-->was_busy = slab_rebalance_move
							|-->
							
					|-->if (slab_rebal.done)
						|-->slab_rebalance_finish //()
						
					|-->else if (was_busy)
						|-->usleep(1000)
						
					|-->if (slab_rebalance_signal == 0)
						|-->pthread_cond_wait(&slab_rebalance_cond, &slabs_rebalance_lock) //等待唤醒
	
	if(start_lru_maintainer)//默认进入该分支
		|-->start_lru_maintainer_thread //(memcached.c)
			|-->do_run_lru_maintainer_thread = 1 //设置变量,用于线程loop
			|-->settings.lru_maintainer_thread = true
			|-->lru_maintainer_thread //(items.c) 创建线程
				|-->while (do_run_lru_maintainer_thread) //进入loop循环
					|-->if (settings.lru_crawler && last_crawler_check != current_time)
						|-->lru_maintainer_crawler_check(cdata, l)//(items.c)
							|-->if (do_run)
								|-->lru_crawler_start //(crawler.c)
									|-->if(stats)
										|-->pthread_cond_signal(&lru_crawler_cond) //将slab_maintenance_thread唤醒

						|-->last_crawler_check = current_time

				|-->slab_automove_reg_t *sam = &slab_automove_default //
					|-->sam->init //(items.c)
						|-->slab_automove_init //(slab_automove.c)
							|-->

					|-->sam->run //(items.c)
						|-->slab_automove_run //(slab_automove.c)
							|-->
	
	|-->if(settings.idle_timeout)//默认为0,不进入该分支
		|-->start_conn_timeout_thread //(memcached.c)
			|-->conn_timeout_thread //(memcached.c)
				|-->while(1) //loop
					|-->oldest_last_cmd = current_time //
					|-->for (i = 0; i < max_fds; i++)
						|-->if (c->state == conn_new_cmd || c->state == conn_read)
							|-->if ((current_time - c->last_cmd_time) > settings.idle_timeout)
								|-->buf[0] = 't'
								|-->memcpy(&buf[1], &i, sizeof(int)) 
								|-->write(c->thread->notify_send_fd, buf, TIMEOUT_MSG_SIZE) //写入数据

						|-->usleep //睡眠
	
	|-->clock_handler //(memcached.c)
		|-->assoc_start_expand //(assoc.c)
			|-->if (curr_items > (hashsize(hashpower) * 3) / 2 && hashpower < HASHPOWER_MAX)
				|-->pthread_cond_signal(&maintenance_cond) //发送信号，唤醒assoc_maintenance_thread线程

	|-->if (settings.socketpath != NULL)//默认settings.socketpath=NULL,所以不会进入该分支 
		|-->server_socket_unix //(memcached.c)
			|-->conn_new //(memcached.c)

	|-->if (settings.socketpath == NULL) //默认进入该分支
		|-->if(settings.port) //默认为11211
			|-->server_sockets(settings.port, tcp_transport, portnumber_file) //(memcached.c) 默认创建tcp
				|-->if (settings.inter == NULL) 默认进入该分支
					|-->server_socket //(memcached.c)
						|-->new_socket //(memcached.c) 创建socket并将之设置为O_NONBLOCK
						|-->setsockopt(sfd, SOL_SOCKET, SO_REUSEADDR, (void *)&flags, sizeof(flags)) 
						|-->setsockopt(sfd, SOL_SOCKET, SO_KEEPALIVE, (void *)&flags, sizeof(flags))
						|-->setsockopt(sfd, SOL_SOCKET, SO_LINGER, (void *)&ling, sizeof(ling))
						|-->setsockopt(sfd, IPPROTO_TCP, TCP_NODELAY, (void *)&flags, sizeof(flags))
						|-->bind, listen
						|-->listen_conn_add = conn_new(sfd, conn_listening, EV_READ | EV_PERSIST, 1, transport, main_base) //(memcached.c)
							|-->c->state = conn_listening //将状态机设置为conn_listening
							|-->event_set(&c->event, sfd, event_flags, event_handler, (void *)c) //将创建的listen句柄绑定到event_handler函数, 当有新的连接到来时调用该函数
								|-->event_handler //(memcached.c) 当listener接收到数据时会调用到该函数
									|-->drive_machine //(memcached.c)
										|-->switch(c->state)
											|-->case conn_listening //监听状态，用于处理新接入的用户请求
												|-->sfd = accept //新连接的fd
												|-->dispatch_conn_new(sfd, conn_new_cmd, EV_READ | EV_PERSIST, DATA_BUFFER_SIZE, c->transport) //(thread.c) 设置新连接的fd状态为conn_new_cmd, listen状态的fd状态保持不变
													|-->item->init_state = conn_new_cmd //将状态机设置为conn_new_cmd，等待用户输入命令
													|-->item->mode = queue_new_conn //(threads.c) 设置mode状态机
													|-->item->event_flags = EV_READ | EV_PERSIST //设置flag
													|-->buf[0] = 'c' 
													|-->write(thread->notify_send_fd, buf, 1) //通过 notify_send_fd 向pipe中写入一个字节'c'来切换到子线程(pipe中不是原子的，所以写入一个字节确保不会出现数据紊乱)

							|-->event_base_set(base, &c->event)

				|-->else //如果设置了settings.inter则进入该分支
					|-->server_socket //解析数据结构,创建更多的server_socket
	

	|-->event_base_loop //(memcached.c) 阻塞在这里，具体实现参见libevent实现
	
	
|-->stop_assoc_maintenance_thread //(assoc.c)
	|-->do_run_maintenance_thread = 0 //设置while 循环退出变量值
	|-->pthread_cond_signal(&maintenance_cond) //发送信号
	
|-->do_slabs_reassign //(slabs.c)
	|-->slab_rebalance_signal = 1
	|-->pthread_cond_signal(&slab_rebalance_cond) //发送信号
	
|-->stop_slab_maintenance_thread //(slabs.c)
	|-->do_run_slab_thread = 0
	|-->do_run_slab_rebalance_thread = 0
	|-->pthread_cond_signal(&slab_rebalance_cond) //发送信号，以便唤醒线程并退出

typedef struct {
    slab_automove_init_func init;
    slab_automove_free_func free;
    slab_automove_run_func run;
} slab_automove_reg_t; //(slab_automove.h)

slab_automove_reg_t slab_automove_default = {
    .init = slab_automove_init,
    .free = slab_automove_free,
    .run = slab_automove_run
};

|-->start_item_crawler_thread //(crawler.c)
	|-->item_crawler_thread //(crawler.c)
		|-->

|-->start_lru_maintainer_thread //(items.c)
	|-->lru_maintainer_thread //(items.c) 创建线程
		|-->slab_automove_reg_t *sam = &slab_automove_default //
			|-->sam->init //(items.c)
				|-->slab_automove_init //(slab_automove.c)
					|-->

			|-->sam->run //(items.c)
				|-->slab_automove_run //(slab_automove.c)
					|-->

|-->do_item_get //(items.c)
	|-->if (is_flushed) //这个item是否在flush_all之前,如果是,则删除
		|-->do_item_unlink //
		|-->do_item_remove //

	|-->else if(it->exptime != 0 && it->exptime <= current_time) //这个item是否过期,过期则删除
		|-->do_item_unlink //
		|-->do_item_remove //

	|-->else //如果这个item没有在flush_all之前也没有过期,则标注为活跃item
		|-->do_item_update //
		

|-->process_lru_command //(memcached.c)
	|-->settings.hot_lru_pct = pct_hot;
    |-->settings.warm_lru_pct = pct_warm;
    |-->settings.hot_max_factor = hot_factor;
    |-->settings.warm_max_factor = factor;

|-->conn_close //(memcached.c)
	|-->event_del(&c->event) //调用epoll删除fd
	|-->conn_cleanup //
